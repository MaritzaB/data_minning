{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instituto Politécnico Nacional\n",
    "\n",
    "Centro de Investigación en Computación\n",
    "\n",
    "Minería de datos I\n",
    "\n",
    "Programación de algoritmos de regresión\n",
    "\n",
    "Presenta: Ana Maritza Bello\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest\n",
    "1. K-Nearest Neighbors\n",
    "1. Neural Networks\n",
    "\n",
    "---\n",
    "1. Con datos propios\n",
    "1. Aplicando reducción de variables\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección y evaluación de modelos\n",
    "\n",
    "## Selección de modelos\n",
    "\n",
    "La selección de modelos es una de las tareas más importantes en el proceso de\n",
    "minería de datos. El objetivo es seleccionar el modelo que mejor se ajuste a los\n",
    "datos y que al mismo tiempo sea simple y fácil de interpretar. La selección de\n",
    "modelos es una tarea difícil porque los modelos más simples no siempre son los\n",
    "que mejor se ajustan a los datos. Por ejemplo, un modelo lineal puede ser muy\n",
    "simple pero no ajustarse bien a los datos. Por otro lado, un modelo muy complejo \n",
    "puede ajustarse muy bien a los datos pero ser difícil de interpretar.\n",
    "\n",
    "La selección de modelos es un proceso iterativo que consiste en probar\n",
    "diferentes modelos y evaluar su desempeño. El desempeño de un modelo se evalúa\n",
    "con base en una medida de exactitud. La medida de exactitud más común es la\n",
    "exactitud de clasificación. La exactitud de clasificación se define como el \n",
    "porcentaje de instancias clasificadas correctamente por el modelo. La exactitud\n",
    "de clasificación se calcula con base en una matriz de confusión. La matriz de\n",
    "confusión es una matriz que muestra el número de instancias clasificadas\n",
    "correctamente e incorrectamente por el modelo. La matriz de confusión se\n",
    "calcula con base en un conjunto de prueba.\n",
    "\n",
    "## Evaluación de modelos\n",
    "\n",
    "Para evaluar el desempeño de un modelo se utiliza un conjunto de prueba. El \n",
    "conjunto de prueba es un conjunto de instancias que no se utilizan para \n",
    "entrenar el modelo. El conjunto de prueba se utiliza para evaluar el desempeño \n",
    "del modelo. El conjunto de prueba debe ser representativo del conjunto de \n",
    "entrenamiento. El conjunto de prueba debe tener la misma distribución de\n",
    "clases que el conjunto de entrenamiento.\n",
    "\n",
    "# Técnicas para mejorar la exactitud de los modelos\n",
    "\n",
    "La exactitud de los modelos se puede mejorar con las siguientes técnicas:\n",
    "\n",
    "1. Selección de variables\n",
    "1. Reducción de variables\n",
    "1. Selección de modelos\n",
    "1. Ajuste de parámetros\n",
    "\n",
    "## Reducción de variables\n",
    "En este proyecto se aplicó la técnica de reducción de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparación de datos\n",
    "\n",
    "La preparación de datos se realizó realizando las siguientes tareas:\n",
    "\n",
    "1. Se adecuó un arreglo bidimensional para la variable salida.\n",
    "1. Los datos categoricos se convirtieron a numéricos.\n",
    "1. Se eliminaron las variables que no se utilizaron en el modelo.\n",
    "1. Se eliminaron las instancias con valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/trajectories.csv')\n",
    "data = data.drop(['id'],axis = 1)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Shuffle the data with numpy\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].apply(lambda x: x.split('-')[1])\n",
    "df['month'] = df['month'].astype(int)\n",
    "df['year'] = df['date'].apply(lambda x: x.split('-')[0])\n",
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical variables into one-hot encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['season'] = le.fit_transform(df['season'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.isna().any(axis=1)\n",
    "rows = rows[rows == True]\n",
    "df.dropna(inplace=True)\n",
    "rows = df.isna().any(axis=1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlación\n",
    "\n",
    "La matriz de correralación se utilizó con el fin de identificar las variables\n",
    "que tienen una correlación alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features\n",
    "feature_cols = ['season', 'spheroid_dist_to_colony', 'sst', 'wnd_ucmp_height_above_ground', 'wnd_vcmp_height_above_ground', 'month', 'year']\n",
    "corr = df[feature_cols].corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, annot=True, cmap='viridis')\n",
    "plt.title('Correlation between features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "El conjunto de prueba es un conjunto de instancias que no se utilizan para\n",
    "entrenar el modelo. El conjunto de prueba se utiliza para evaluar el desempeño \n",
    "del modelo. El conjunto de prueba se obtiene dividiendo el conjunto de datos en\n",
    "dos partes: una parte para entrenar el modelo y otra parte para probar el\n",
    "modelo.\n",
    "\n",
    "La parte para entrenar el modelo se conoce como conjunto de entrenamiento y la\n",
    "parte para probar el modelo se conoce como conjunto de prueba. El conjunto de\n",
    "entrenamiento se utiliza para entrenar el modelo y el conjunto de prueba se\n",
    "utiliza para evaluar el desempeño del modelo.\n",
    "\n",
    "El conjunto de entrenamiento debe ser más grande que el conjunto de prueba. La\n",
    "proporción entre el conjunto de entrenamiento y el conjunto de prueba depende\n",
    "del tamaño del conjunto de datos. En general, el conjunto de entrenamiento debe\n",
    "ser el 70% del conjunto de datos y el conjunto de prueba debe ser el 30% del\n",
    "conjunto de datos.\n",
    "\n",
    "Para este proyecto se utilizará una proporción de 80% para el conjunto de\n",
    "entrenamiento y 20% para el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Multitarget array\n",
    "y = df[['longitude', 'latitude']].values\n",
    "\n",
    "# Features\n",
    "cols_to_drop = ['latitude', 'longitude', 'name', 'date']\n",
    "X = df.drop(cols_to_drop, axis = 1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=83, shuffle=True)\n",
    "\n",
    "print(\" X_train shape: \", X_train.shape, \"\\n\",\n",
    "      \"y_train shape: \", y_train.shape, \"\\n\",\n",
    "      \"X_test shape: \", X_test.shape, \"\\n\",\n",
    "      \"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de regresión\n",
    "\n",
    "El problema de regresión consiste en predecir el valor de una variable numérica\n",
    "a partir de los valores de otras variables numéricas. Particularmente en este\n",
    "proyecto se presenta un problema de **regresión multi-salida**. Esto significa\n",
    "que se tienen varias variables de salida. Dado que se pretende predecir el valor\n",
    "de un punto en el espacio, se tienen dos variables de salida: la coordenada _x_\n",
    "que es la longitud y la coordenada _y_ que es la latitud.\n",
    "\n",
    "Para resolver el problema de regresión multi-salida se utilizó un módulo de \n",
    "Python llamado **sklearn.multioutput**. Este módulo contiene varios algoritmos\n",
    "de regresión multi-salida. En este proyecto se utilizaron los siguientes:\n",
    "\n",
    "1. Random Forest Regressor\n",
    "1. K-Neighbors Regressor\n",
    "1. Neural Network Regressor\n",
    "\n",
    "## Modelo de multi-salida usando el algoritmo de Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "multioutput_model_RF = MultiOutputRegressor(RandomForestRegressor(n_estimators=10, max_depth=12, random_state=83))\n",
    "multioutput_model_RF.fit(X_train, y_train)\n",
    "y1_pred = multioutput_model_RF.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y1_pred[:, 0], y1_pred[:, 1], c='c', label='Predicted position with RF', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with RF')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de multi-salida usando el algoritmo de K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "multioutput_model_KNN = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=5))\n",
    "multioutput_model_KNN.fit(X_train, y_train)\n",
    "y3_pred = multioutput_model_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y3_pred[:, 0], y3_pred[:, 1], c='gray', label='Predicted position with KNN', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with KNN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de multi-salida usando una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Crear modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)\n",
    "model.summary()\n",
    "\n",
    "y4_pred = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y4_pred[:, 0], y4_pred[:, 1], c='green', label='Predicted position', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with NN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de modelos\n",
    "\n",
    "Las medidas de exactitud que se utilizaron para evaluar los modelos fueron:\n",
    "\n",
    "1. **Error absoluto medio**. El error absoluto medio se define como la media de\n",
    "los errores absolutos. El error absoluto se define como la diferencia entre el\n",
    "valor real y el valor predicho. El error absoluto medio se calcula con base en\n",
    "el conjunto de prueba.\n",
    "1. **Error cuadrático medio**. El error cuadrático medio se define como la media\n",
    "de los errores cuadráticos. El error cuadrático se define como el cuadrado de la\n",
    "diferencia entre el valor real y el valor predicho. El error cuadrático medio se\n",
    "calcula con base en el conjunto de prueba.\n",
    "1. **Coeficiente de determinación**. El coeficiente de determinación se define\n",
    "como la proporción de la varianza total de la variable de salida que es\n",
    "explicada por el modelo. El coeficiente de determinación se calcula con base en\n",
    "el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Evaluate MSE and plot results for each model\n",
    "\n",
    "print('MSE for RF: ', mean_squared_error(y_test, y1_pred))\n",
    "print('MSE for KNN: ', mean_squared_error(y_test, y3_pred))\n",
    "print('MSE for NN: ', mean_squared_error(y_test, y4_pred))\n",
    "print(\"\\n\")\n",
    "print('MAE for RF: ', mean_absolute_error(y_test, y1_pred))\n",
    "print('MAE for KNN: ', mean_absolute_error(y_test, y3_pred))\n",
    "print('MAE for NN: ', mean_absolute_error(y_test, y4_pred))\n",
    "print(\"\\n\")\n",
    "print('R2 for RF: ', r2_score(y_test, y1_pred))\n",
    "print('R2 for KNN: ', r2_score(y_test, y3_pred))\n",
    "print('R2 for NN: ', r2_score(y_test, y4_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de componentes principales\n",
    "\n",
    "El análisis de componentes principales es una técnica de reducción de variables.\n",
    "El análisis de componentes principales se utiliza para reducir el número de\n",
    "variables de un conjunto de datos. \n",
    "\n",
    "Para este proyecto se utilizó el módulo de Python llamado\n",
    "**sklearn.decomposition**.\n",
    "\n",
    "Los componentes principales se calcularon con base en el conjunto de\n",
    "entrenamiento se estableció que el número de componentes principales es 2.\n",
    "\n",
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de multi-salida usando el algoritmo de Random Forest con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "multioutput_model_RF.fit(X_train_pca, y_train)\n",
    "y1_pred_pca = multioutput_model_RF.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de multi-salida usando el algoritmo de K-Nearest Neighbors con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "multioutput_model_KNN.fit(X_train_pca, y_train)\n",
    "y3_pred_pca = multioutput_model_KNN.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de multi-salida usando una red neuronal con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "X_train_pca.shape\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_pca.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "model.fit(X_train_pca, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "model.evaluate(X_test_pca, y_test, verbose=1)\n",
    "y4_pred_pca = model.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y1_pred_pca[:, 0], y1_pred_pca[:, 1], c='c', label='Predicted position with RF', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with RF and PCA')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y3_pred_pca[:, 0], y3_pred_pca[:, 1], c='gray', label='Predicted position with KNN', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with KNN and PCA')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test[:, 0], y_test[:, 1], c='red', label='Real position')\n",
    "plt.scatter(y4_pred_pca[:, 0], y4_pred_pca[:, 1], c='green', label='Predicted position', s=10, marker='x')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Real and predicted occurrences of the species with NN and PCA')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de la evaluación de modelos de regresión con reducción de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with results for each model\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable(['Model', 'MSE', 'MAE', 'R2'])\n",
    "table.add_row(['RF', mean_squared_error(y_test, y1_pred), mean_absolute_error(y_test, y1_pred), r2_score(y_test, y1_pred)])\n",
    "table.add_row(['KNN', mean_squared_error(y_test, y3_pred), mean_absolute_error(y_test, y3_pred), r2_score(y_test, y3_pred)])\n",
    "table.add_row(['NN', mean_squared_error(y_test, y4_pred), mean_absolute_error(y_test, y4_pred), r2_score(y_test, y4_pred)])\n",
    "table.add_row(['RF + PCA', mean_squared_error(y_test, y1_pred_pca), mean_absolute_error(y_test, y1_pred_pca), r2_score(y_test, y1_pred_pca)])\n",
    "table.add_row(['KNN + PCA', mean_squared_error(y_test, y3_pred_pca), mean_absolute_error(y_test, y3_pred_pca), r2_score(y_test, y3_pred_pca)])\n",
    "table.add_row(['NN + PCA', mean_squared_error(y_test, y4_pred_pca), mean_absolute_error(y_test, y4_pred_pca), r2_score(y_test, y4_pred_pca)])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "El modelo que mejor se ajusta a los datos es el modelo de regresión multi-salida\n",
    "con el algoritmo de Random Forest. El modelo de regresión multi-salida con el\n",
    "algoritmo de Random Forest tiene un error absoluto medio de 0.1438, un error \n",
    "cuadrático medio de 0.091 y un coeficiente de determinación de 0.996.\n",
    "\n",
    "Sin embargo, el modelo de regresión multi-salida con el algoritmo de K-Nearest\n",
    "también se ajusta bien a los datos. El modelo de regresión multi-salida con el\n",
    "algoritmo de K-Nearest tiene un error absoluto medio de 0.19, un error\n",
    "cuadrático medio de 0.36 y un coeficiente de determinación de 0.9871.\n",
    "\n",
    "La Red Neutonal obtuvo buenos resultados sin la reducción de variables, pero\n",
    "con la reducción de variables los resultados no fueron buenos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
