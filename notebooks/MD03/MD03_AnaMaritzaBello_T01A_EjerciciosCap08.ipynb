{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instituto Politécnico Nacional\n",
    "\n",
    "Centro de Investigación en Computación\n",
    "\n",
    "Minería de datos I\n",
    "\n",
    "Ejercicios del capítulo 8.\n",
    "\n",
    "Ejercicios 1 al 16\n",
    "\n",
    "Presenta: Ana Maritza Bello\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Resuma brevemente los pasos principales de la clasificación del árbol de\n",
    "decisiones.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Los pasos principales de la clasificación del árbol de decisiones son:\n",
    "\n",
    "1. Crear un nodo raíz para el conjunto de entrenamiento. Este nodo raíz contiene\n",
    "   todos los registros de entrenamiento.\n",
    "2. Si todos los registros en el nodo raíz pertenecen a la misma clase, entonces se\n",
    "   etiqueta el nodo con esa clase y se detiene.\n",
    "3. Si el conjunto de atributos es vacío, entonces se etiqueta el nodo con la\n",
    "   clase más común y se detiene.\n",
    "4. De lo contrario, aplicamos la función de selección de atributos para\n",
    "   seleccionar el mejor atributo para dividir los registros. Esta función puede\n",
    "   usar la ganancia de información o el índice Gini para seleccionar la mejor\n",
    "   manera de dividir los registros. El criterio de selección de atributos\n",
    "   consiste en dividir los registros en subconjuntos que sean lo más puros\n",
    "   posible.\n",
    "5. Creamos un nodo de decisión basado en el atributo seleccionado.\n",
    "6. Creamos un subárbol para cada valor del atributo seleccionado y lo aplicamos\n",
    "   a los subconjuntos de registros creados. Es decir, si el atributo seleccionado\n",
    "   es A, entonces el subárbol tendrá tantos nodos como valores tenga A.\n",
    "7. Aplicamos los pasos 1 a 6 para cada nodo del árbol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 ¿Por qué es útil la poda de árboles en la inducción de árboles de decisión?\n",
    "¿Cuál es el inconveniente de utilizar un conjunto separado de tuplas para\n",
    "evaluar la poda?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "La poda de árboles es útil en la inducción de árboles de decisión porque nos\n",
    "ayuda a evitar el sobreajuste. Los árboles de decisión tienden a sobreajustarse\n",
    "a los datos de entrenamiento, es decir, el árbol se ajusta bastante al ruido de\n",
    "los datos de entrenamiento y no generaliza bien cuando tenemos nuevos datos. La poda de árboles se puede realizar de dos maneras: \n",
    "\n",
    "1. Poda pre-poda: se detiene la construcción del árbol antes de que se alcance\n",
    "   el ajuste perfecto a los datos de entrenamiento.\n",
    "2. Poda posterior: se construye el árbol completo y luego se poda el árbol\n",
    "    resultante.\n",
    "\n",
    "El inconveniente de utilizar un conjunto separado de tuplas para evaluar la poda\n",
    "podría ser que el conjunto de tuplas de prueba no sea representativo de los\n",
    "datos reales. Por ejemplo, si el conjunto de tuplas de prueba es muy pequeño, la\n",
    "poda puede llevar a decisiones subóptimas. Dicho de otra forma, podríamos estar\n",
    "eliminando nodos que son importantes para la clasificación de los datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Dado un árbol de decisión, tiene la opción de \n",
    "\n",
    "(a) convertir el árbol de decisión en reglas y luego podar las reglas\n",
    "resultantes, \n",
    "\n",
    "(b) podar el árbol de decisión y luego convertir el árbol podado en reglas.\n",
    "\n",
    "¿Qué ventaja tiene (a) sobre (b)?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "La ventaja de (a) sobre (b) es que al convertir el árbol de decisión en reglas,\n",
    "cada regla representa una ruta desde la raíz hasta una hoja del árbol. Por lo\n",
    "que al podar las reglas resultantes, se podan las rutas que no son importantes y\n",
    "se conservan las rutas que son importantes para la clasificación de los datos.\n",
    "\n",
    "Si podaramos primero el árbol y luego lo convirtiéramos en reglas, podríamos\n",
    "perder información importante para la clasificación de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.4 Es importante calcular la complejidad computacional del peor de los casos\n",
    "del algoritmo del árbol de decisión. Dado el conjunto de datos, _D_, el número\n",
    "de atributos, _n_, y el número de tuplas de entrenamiento, _|D|_, muestran que\n",
    "el costo computacional de hacer crecer un árbol es como máximo _n*|D|*log(|D|)_.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "En el peor de los casos, para cada nodo del árbol debemos de evaluar todos los\n",
    "atributos para determinar cuál es el mejor atributo para dividir los registros.\n",
    "Esto implica un costo de _n_ operaciones.\n",
    "\n",
    "Después de seleccionar el mejor atributo, debemos de dividir los registros en\n",
    "subconjuntos. Esto implica un costo de _|D|_ operaciones ya que debemos de\n",
    "recorrer todos los registros.\n",
    "\n",
    "Ya que cada nivel del árbol se reduce a la mitad, el número de niveles del árbol\n",
    "es _log(|D|)_. Por lo que el costo computacional lo obtenemos multiplicando\n",
    "estos tres factores: _n*|D|*log(|D|)_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.5 Dado un conjunto de datos de 5 GB con 50 atributos (cada uno con 100 valores\n",
    "distintos) y 512 MB de memoria principal en su computadora portátil, describa un\n",
    "método eficiente que construya árboles de decisión en conjuntos de datos tan\n",
    "grandes. Justifique su respuesta mediante un cálculo aproximado del uso de su\n",
    "memoria principal.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Para construir árboles de decisión en conjuntos de datos tan grandes, podemos\n",
    "utilizar un muestreo aleatorio o un muestreo estratificado. El muestreo\n",
    "aleatorio consiste en seleccionar un subconjunto de tuplas de manera aleatoria.\n",
    "El muestreo estratificado consiste en seleccionar un subconjunto de tuplas de\n",
    "manera que la distribución de clases sea la misma que la del conjunto de datos\n",
    "original. Esto reduce la cantidad de tuplas que se utilizan para construir el\n",
    "árbol.\n",
    "\n",
    "Por ejemplo, si utilizamos un muestreo aleatorio del 10%, entonces el conjunto\n",
    "de datos se reduce a 500 MB. Si tenemos 50 atributos, cada uno con 100 valores\n",
    "distintos, entonces la cantidad de memoria que se utiliza para construir el\n",
    "árbol suponiendo que cada valor de cada atributo se almacena en 4 bytes es:\n",
    "\n",
    "```\n",
    "500 MB + 50 * 100 * 4 bytes = 500 MB + 20 KB = 500 MB + 0.02 MB = 500.02 MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.6 ¿Por qué la clasificación bayesiana ingenua se denomina “ingenua”? Resuma\n",
    "brevemente las ideas principales de la clasificación bayesiana ingenua.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "La clasificación bayesiana ingenua se denomina “ingenua” porque asume que los\n",
    "atributos son independientes entre sí. Es decir, asume que la presencia de un\n",
    "atributo no afecta la presencia de otro atributo. Esta suposición simplifica\n",
    "significativamente los cálculos y hace que el modelo sea más fácil de construir\n",
    "y más rápido de entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.7 La siguiente tabla consta de datos de capacitación de una base de datos de empleados. Los datos se han generalizado. Por ejemplo, “31. . . 35” por edad representa el rango de edad de 31 a 35 años.\n",
    "Para una entrada de fila determinada, el recuento representa el número de tuplas\n",
    "de datos que tienen los valores de departamento, estado, edad y salario\n",
    "indicados en esa fila.\n",
    "\n",
    "Departamento | Estado | Edad | Salario | Recuento\n",
    "--- | --- | --- | --- | ---\n",
    "sales | senior | 31...35 | 46K...50K | 30\n",
    "sales | junior | 26...30 | 26K...30K | 40\n",
    "sales | junior | 31...35 | 31K...35K | 40\n",
    "systems | junior | 21...25 | 46K...50K | 20\n",
    "systems | senior | 31...35 | 66K...70K | 5\n",
    "systems | junior | 26...30 | 46K...50K | 3\n",
    "systems | senior | 41...45 | 66K...70K | 3\n",
    "marketing | senior | 36...40 | 46K...50K | 10\n",
    "marketing | junior | 31...35 | 41K...45K | 4\n",
    "secretary | senior | 46...50 | 36K...40K | 4\n",
    "secretary | junior | 26...30 | 26K...30K | 6\n",
    "\n",
    "Sea el estado el atributo de etiqueta de clase.\n",
    "\n",
    "(a) ¿Cómo modificaría el algoritmo básico del árbol de decisión para tener en cuenta el recuento de cada tupla de datos generalizados (es decir, de cada entrada de fila)?\n",
    "\n",
    "(b) Utilice su algoritmo para construir un árbol de decisión a partir de los datos dados.\n",
    "\n",
    "(c) Dada una tupla de datos que tiene los valores “sistemas”, “26...30” y\n",
    "“46–50K” para los atributos departamento, edad y salario, respectivamente.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "(a) Para modificar el algoritmo básico del árbol de decisión para tener en cuenta el recuento de cada tupla de datos generalizados, debemos de modificar la función de selección de atributos. En lugar de seleccionar el atributo que maximice la ganancia de información o el índice Gini, debemos de seleccionar el atributo que maximice la ganancia de información ponderada o el índice Gini ponderado. La ganancia de información ponderada o el índice Gini ponderado se calculan de la siguiente manera:\n",
    "\n",
    "```\n",
    "Ganancia de información ponderada = Ganancia de información * Recuento de tuplas en el nodo.\n",
    "Índice Gini ponderado = Índice Gini * Recuento de tuplas en el nodo.\n",
    "```\n",
    "\n",
    "Debemos considerar ajustar el umbral de parada para evitar divisiones en nodos\n",
    "con muy pocas tuplas. Por ejemplo, si el recuento de tuplas en el nodo es menor\n",
    "que 10, entonces no dividimos el nodo y etiquetamos el nodo con la clase más\n",
    "común.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.8 RainForest es un algoritmo escalable para la inducción de árboles de\n",
    "decisión. Desarrollar un algoritmo de clasificación bayesiano ingenuo y\n",
    "escalable que requiera solo un escaneo de todo el conjunto de datos para la\n",
    "mayoría de las bases de datos. Analice si dicho algoritmo se puede perfeccionar\n",
    "para incorporar un refuerzo que mejore aún más la precisión de su clasificación.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "El algoritmo de clasificación bayesiano ingenuo y escalable que requiera solo un\n",
    "escaneo de todo el conjunto de datos para la mayoría de las bases de datos es el\n",
    "siguiente:\n",
    "\n",
    "1. Recorrer una sola vez el conjunto de datos para contar el número de tuplas\n",
    "   que pertenecen a cada clase. Con esto obtenemos la probabilidad de cada\n",
    "   clase.\n",
    "   Esta tabla es mucho menor que el conjunto de datos original, ya que depende\n",
    "   solo del número de clases, no del número de tuplas.\n",
    "\n",
    "Para incorporar un refuerzo que mejore aún más la precisión de la clasificación,\n",
    "podemos utilizar un refuerzo de peso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.9 Diseñe un método eficiente que realice una clasificación bayesiana ingenua y\n",
    "efectiva sobre un flujo de datos infinito (es decir, puede escanear el flujo de\n",
    "datos solo una vez). Si quisiéramos descubrir la evolución de tales esquemas de\n",
    "clasificación (por ejemplo, comparando el esquema de clasificación actual con\n",
    "esquemas anteriores como el de hace una semana), ¿qué diseño modificado\n",
    "sugeriría?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Para esta tarea podemos utilizar un enfoque de aprendizaje incremental. Este\n",
    "enfoque consiste en actualizar el modelo de clasificación cada vez que se recibe\n",
    "una nueva tupla de datos. Asi, podemos calcular y actualizar las probabilidades\n",
    "apriori de las clases y las probabilidades condicionales de los atributos a\n",
    "medida que se reciben nuevas tuplas de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.10 Demuestre que la precisión es una función de la sensibilidad y la\n",
    "especificidad, es decir, demuestre la ecuación. (8.25).\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Sean:\n",
    "\n",
    "$$ sensitivity = \\frac{TP}{P}$$\n",
    "$$ specificity = \\frac{TN}{N}$$\n",
    "\n",
    "donde:\n",
    "TP = True Positive\n",
    "TN = True Negative\n",
    "P = Positive\n",
    "N = Negative\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$ accuracy = \\frac{TP + TN}{P+N} = \\frac{TP}{P+N} + \\frac{TN}{P+N}$$\n",
    "\n",
    "$$ = \\frac{TP}{P+N} * \\frac{P}{P} + \\frac{TN}{P+N} * \\frac{N}{N}$$\n",
    "\n",
    "$$ = \\frac{P}{TP+TN} * sensitivity + \\frac{N}{TP+TN} * specificity $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.11 La media armónica es uno de varios tipos de promedios. El capítulo 2 analizó cómo calcular la media aritmética, que es en lo que la mayoría de la gente suele pensar cuando calcula un promedio. La media armónica, H, de los números reales positivos, _x1, x2,..., xn_, se define como\n",
    "\n",
    "$$ H = \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + ... + \\frac{1}{x_n}} $$\n",
    "\n",
    "$$ = \\frac{n}{\\sum_{i=1}^{n} \\frac{1}{x_i}} $$\n",
    "\n",
    "La medida F es la media armónica de precisión y recuperación. Utilice este hecho\n",
    "para derivar la ecuación. (8.28) para F. Además, escriba $F_β$ como una función\n",
    "de verdaderos positivos, falsos negativos y falsos positivos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.12 Las tuplas de datos de la figura 8.25 se ordenan por valor de probabilidad\n",
    "decreciente, según lo devuelto por un clasificador. Para cada tupla, calcule los\n",
    "valores del número de verdaderos positivos (TP), falsos positivos (FP),\n",
    "verdaderos negativos (TN) y falsos negativos (FN). Calcule la tasa de verdaderos\n",
    "positivos (TPR) y la tasa de falsos positivos (FPR). Trazar la curva ROC para\n",
    "los datos.\n",
    "\n",
    "Tupla | Clase | Probabilidad\n",
    "--- | --- | ---\n",
    "1 | P | 0.95\n",
    "2 | N | 0.85\n",
    "3 | P | 0.78\n",
    "4 | P | 0.66\n",
    "5 | N | 0.60\n",
    "6 | P | 0.55\n",
    "7 | N | 0.53\n",
    "8 | N | 0.52\n",
    "9 | N | 0.51\n",
    "10 | P | 0.40\n",
    "\n",
    "Las tuplas están ordenadas en orden decreciente de probabilidad, donde el valor\n",
    "de la probabilidad está dada por un clasificador probabilístico.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "La medida F es la media armónica de precisión y recuperación. La precisión se\n",
    "define como:\n",
    "\n",
    "$$ precision = \\frac{TP}{TP+FP} $$\n",
    "\n",
    "La recuperación se define como:\n",
    "\n",
    "$$ recall = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "La media armónica de precisión y recuperación se define como:\n",
    "\n",
    "$$ F = \\frac{2 * precision * recall}{precision + recall} $$\n",
    "\n",
    "Por lo que:\n",
    "\n",
    "$$ F_β = (1 + β^2) * \\frac{TP}{(1+β^2) * TP + (β^2 * FN)+ FP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuple</th>\n",
       "      <th>tuple_class</th>\n",
       "      <th>probability</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>P</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>P</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>P</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>P</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tuple tuple_class  probability  TP  FP  TN  FN  TPR  FPR\n",
       "0      1           P         0.95   1   0   5   4  0.2  0.0\n",
       "1      2           N         0.85   1   1   4   4  0.2  0.2\n",
       "2      3           P         0.78   2   1   4   3  0.4  0.2\n",
       "3      4           P         0.66   3   1   4   2  0.6  0.2\n",
       "4      5           N         0.60   3   2   3   2  0.6  0.4\n",
       "5      6           P         0.55   4   2   3   1  0.8  0.4\n",
       "6      7           N         0.53   4   3   2   1  0.8  0.6\n",
       "7      8           N         0.52   4   4   1   1  0.8  0.8\n",
       "8      9           N         0.51   4   5   0   1  0.8  1.0\n",
       "9     10           P         0.40   5   5   0   0  1.0  1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tuple = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "tuple_class = ['P', 'N', 'P', 'P', 'N', 'P', 'N', 'N', 'N', 'P']\n",
    "probability = [0.95, 0.85, 0.78, 0.66, 0.60, 0.55, 0.53, 0.52, 0.51, 0.40]\n",
    "\n",
    "df = pd.DataFrame({'tuple': tuple, 'tuple_class': tuple_class, 'probability': probability})\n",
    "df['TP'] = [1, 1, 2, 3, 3, 4, 4, 4, 4, 5]\n",
    "df['FP'] = [0, 1, 1, 1, 2, 2, 3, 4, 5, 5]\n",
    "df['TN'] = [5, 4, 4, 4, 3, 3, 2, 1, 0, 0]\n",
    "df['FN'] = [4, 4, 3, 2, 2, 1, 1, 1, 1, 0]\n",
    "df['TPR'] = df['TP'] / (df['TP'] + df['FN'])\n",
    "df['FPR'] = df['FP'] / (df['TP'] + df['FN'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBxElEQVR4nO3dfVxUZf7/8feAznAnqEuCN1Oopelq4E3yQzMrKezGdLuj1dLYsjs1N3JT0sSbkjbLbNWyLLPUVsy1crPFVVorjbJVyUrFvMtSQVmLEUxQ5vr90dfZJUAZAgaOr+fjcR7LXHNd53zO2bZ57znXOcdmjDECAACwCD9fFwAAAFCTCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAzmjhwoWy2WyepVGjRmrdurXuuusuHThwoMIxxhgtWrRIl19+uZo2baqgoCB17dpVU6dOVVFRUaXbevvtt3XttdcqPDxcdrtdrVq10m233aYPPvigSrWeOHFCzz33nGJjYxUWFqaAgAB16NBBo0aN0s6dO6u1/wAaHhvvlgJwJgsXLlRSUpKmTp2qtm3b6sSJE/r000+1cOFCRUVF6auvvlJAQICnf2lpqYYMGaJly5apb9++uummmxQUFKSPP/5Yb775pjp37qy1a9cqIiLCM8YYoz/84Q9auHChunXrpltuuUWRkZE6dOiQ3n77bW3atEkbNmxQ7969K60zPz9fAwYM0KZNm3TDDTcoPj5eISEhysnJ0dKlS5Wbm6uSkpJaPVYA6gkDAGfw2muvGUnm888/L9M+btw4I8mkp6eXaZ8+fbqRZMaOHVtuXStXrjR+fn5mwIABZdpnzJhhJJk//vGPxu12lxv3xhtvmM8+++yMdV5//fXGz8/PLF++vNx3J06cMI888sgZx1fVyZMnTXFxcY2sC0DtINwAOKPKws17771nJJnp06d72o4fP26aNWtmOnToYE6ePFnh+pKSkowkk5WV5RnTvHlzc/HFF5tTp05Vq8ZPP/3USDIjRoyoUv9+/fqZfv36lWsfPny4ueCCCzyf9+7daySZGTNmmOeee860a9fO+Pn5mU8//dT4+/ubyZMnl1vHjh07jCQze/ZsT9sPP/xgxowZY9q0aWPsdrtp3769eeqpp0xpaanX+wrg7JhzA6Ba9u3bJ0lq1qyZp239+vX64YcfNGTIEDVq1KjCccOGDZMkvffee54xR48e1ZAhQ+Tv71+tWlauXClJuvPOO6s1/mxee+01zZ49W/fee6+effZZtWzZUv369dOyZcvK9U1PT5e/v79uvfVWSdLx48fVr18/LV68WMOGDdNf/vIX9enTRykpKUpOTq6VeoFzXcX/9gGAXygoKFB+fr5OnDihzz77TFOmTJHD4dANN9zg6bNt2zZJUnR0dKXrOf3d9u3by/xn165dq11bTazjTL7//nvt2rVL5513nqctMTFR9913n7766it16dLF056enq5+/fp55hTNnDlTu3fv1pYtW3TRRRdJku677z61atVKM2bM0COPPCKn01krdQPnKs7cAKiS+Ph4nXfeeXI6nbrlllsUHByslStXqk2bNp4+x44dkyQ1adKk0vWc/s7lcpX5zzONOZuaWMeZ3HzzzWWCjSTddNNNatSokdLT0z1tX331lbZt26bExERP21tvvaW+ffuqWbNmys/P9yzx8fEqLS3VRx99VCs1A+cyztwAqJK5c+eqQ4cOKigo0IIFC/TRRx/J4XCU6XM6XJwOORX5ZQAKDQ0965iz+d91NG3atNrrqUzbtm3LtYWHh6t///5atmyZpk2bJunnszaNGjXSTTfd5On3zTffaOvWreXC0WmHDx+u8XqBcx3hBkCV9OrVSz179pQkDR48WJdddpmGDBminJwchYSESJI6deokSdq6dasGDx5c4Xq2bt0qSercubMk6eKLL5Ykffnll5WOOZv/XUffvn3P2t9ms8lU8BSM0tLSCvsHBgZW2H777bcrKSlJ2dnZiomJ0bJly9S/f3+Fh4d7+rjdbl199dV69NFHK1xHhw4dzlovAO9wWQqA1/z9/ZWWlqaDBw9qzpw5nvbLLrtMTZs21ZtvvllpUHjjjTckyTNX57LLLlOzZs3017/+tdIxZzNw4EBJ0uLFi6vUv1mzZvrxxx/LtX/77bdebXfw4MGy2+1KT09Xdna2du7cqdtvv71Mn/bt26uwsFDx8fEVLueff75X2wRwdoQbANVyxRVXqFevXpo1a5ZOnDghSQoKCtLYsWOVk5OjCRMmlBuzatUqLVy4UAkJCfp//+//ecaMGzdO27dv17hx4yo8o7J48WJt3Lix0lri4uI0YMAAvfLKK3rnnXfKfV9SUqKxY8d6Prdv3147duzQkSNHPG1ffPGFNmzYUOX9l6SmTZsqISFBy5Yt09KlS2W328udfbrtttuUlZWl1atXlxv/448/6tSpU15tE8DZ8YRiAGd0+gnFn3/+ueey1GnLly/XrbfeqhdffFH333+/pJ8v7SQmJupvf/ubLr/8ct18880KDAzU+vXrtXjxYnXq1EmZmZllnlDsdrt11113adGiRerevbvnCcW5ubl65513tHHjRn3yySeKi4urtM4jR47ommuu0RdffKGBAweqf//+Cg4O1jfffKOlS5fq0KFDKi4ulvTz3VVdunRRdHS07r77bh0+fFjz5s1TRESEXC6X5zb3ffv2qW3btpoxY0aZcPS/lixZojvuuENNmjTRFVdc4bkt/bTjx4+rb9++2rp1q+666y716NFDRUVF+vLLL7V8+XLt27evzGUsADXAt4/ZAVDfVfYQP2OMKS0tNe3btzft27cv8wC+0tJS89prr5k+ffqY0NBQExAQYH7729+aKVOmmMLCwkq3tXz5cnPNNdeY5s2bm0aNGpmWLVuaxMREs27duirVevz4cfPMM8+YSy+91ISEhBi73W4uuugiM3r0aLNr164yfRcvXmzatWtn7Ha7iYmJMatXrz7jQ/wq43K5TGBgoJFkFi9eXGGfY8eOmZSUFHPhhRcau91uwsPDTe/evc0zzzxjSkpKqrRvAKqOMzcAAMBSmHMDAAAshXADAAAshXADAAAshXADAAAshXADAAAshXADAAAs5Zx7t5Tb7dbBgwfVpEkT2Ww2X5cDAACqwBijY8eOqVWrVvLzO/O5mXMu3Bw8eFBOp9PXZQAAgGr47rvv1KZNmzP2OefCTZMmTST9fHBCQ0N9XA0AAKgKl8slp9Pp+R0/k3Mu3Jy+FBUaGkq4AQCgganKlBImFAMAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEvxabj56KOPNHDgQLVq1Uo2m03vvPPOWcesW7dO3bt3l8Ph0IUXXqiFCxfWep0AAKDh8Gm4KSoqUnR0tObOnVul/nv37tX111+vK6+8UtnZ2frjH/+oe+65R6tXr67lSgEAQEPh0xdnXnvttbr22mur3H/evHlq27atnn32WUlSp06dtH79ej333HNKSEiorTIBAEBVGCMdP/7z30FBUhVeclkbGtScm6ysLMXHx5dpS0hIUFZWVqVjiouL5XK5yiwAAKAWHD8uhYT8vJwOOT7QoMJNbm6uIiIiyrRFRETI5XLpp59+qnBMWlqawsLCPIvT6ayLUgEAgI80qHBTHSkpKSooKPAs3333na9LAgAAtcinc268FRkZqby8vDJteXl5Cg0NVWBgYIVjHA6HHA5HXZQHAADqgQZ15iYuLk6ZmZll2tasWaO4uDgfVQQAAOobn4abwsJCZWdnKzs7W9LPt3pnZ2dr//79kn6+pDRs2DBP//vvv1979uzRo48+qh07duiFF17QsmXL9PDDD/uifAAAUA/5NNz8+9//Vrdu3dStWzdJUnJysrp166ZJkyZJkg4dOuQJOpLUtm1brVq1SmvWrFF0dLSeffZZvfLKK9wGDgAAPGzGGOPrIuqSy+VSWFiYCgoKFBoa6utyAACwjqKin28Dl6TCQik4uMZW7c3vd4OacwMAAHA2hBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGApPg83c+fOVVRUlAICAhQbG6uNGzdW2vfkyZOaOnWq2rdvr4CAAEVHRysjI6MOqwUAAPWdT8NNenq6kpOTlZqaqs2bNys6OloJCQk6fPhwhf0nTpyol156SbNnz9a2bdt0//3363e/+522bNlSx5UDAID6ymaMMb7aeGxsrC699FLNmTNHkuR2u+V0OjV69GiNHz++XP9WrVppwoQJGjlypKft5ptvVmBgoBYvXlylbbpcLoWFhamgoEChoaE1syMAAEAqKpJCQn7+u7BQCg6usVV78/vtszM3JSUl2rRpk+Lj4/9bjJ+f4uPjlZWVVeGY4uJiBQQElGkLDAzU+vXrK91OcXGxXC5XmQUAAFiXz8JNfn6+SktLFRERUaY9IiJCubm5FY5JSEjQzJkz9c0338jtdmvNmjVasWKFDh06VOl20tLSFBYW5lmcTmeN7gcAAKhffD6h2BvPP/+8LrroIl188cWy2+0aNWqUkpKS5OdX+W6kpKSooKDAs3z33Xd1WDEAAKhrPgs34eHh8vf3V15eXpn2vLw8RUZGVjjmvPPO0zvvvKOioiJ9++232rFjh0JCQtSuXbtKt+NwOBQaGlpmAQAA1uWzcGO329WjRw9lZmZ62txutzIzMxUXF3fGsQEBAWrdurVOnTqlv/3tbxo0aFBtlwsAABqIRr7ceHJysoYPH66ePXuqV69emjVrloqKipSUlCRJGjZsmFq3bq20tDRJ0meffaYDBw4oJiZGBw4c0OTJk+V2u/Xoo4/6cjcAAEA94tNwk5iYqCNHjmjSpEnKzc1VTEyMMjIyPJOM9+/fX2Y+zYkTJzRx4kTt2bNHISEhuu6667Ro0SI1bdrUR3sAAADqG58+58YXeM4NAAC15Fx/zg0AAEBtINwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABL8Xm4mTt3rqKiohQQEKDY2Fht3LjxjP1nzZqljh07KjAwUE6nUw8//LBOnDhRR9UCAID6zqfhJj09XcnJyUpNTdXmzZsVHR2thIQEHT58uML+b775psaPH6/U1FRt375dr776qtLT0/XYY4/VceUAAKC+shljjK82Hhsbq0svvVRz5syRJLndbjmdTo0ePVrjx48v13/UqFHavn27MjMzPW2PPPKIPvvsM61fv75K23S5XAoLC1NBQYFCQ0NrZkcAKzJGOn7c11UAaEiKiqSIiJ//LiyUgoNrbNXe/H43qrGteqmkpESbNm1SSkqKp83Pz0/x8fHKysqqcEzv3r21ePFibdy4Ub169dKePXv0/vvv684776x0O8XFxSouLvZ8drlcNbcTgFUZI112mfTJJ76uBAC85rNwk5+fr9LSUkWcTnj/JyIiQjt27KhwzJAhQ5Sfn6/LLrtMxhidOnVK999//xkvS6WlpWnKlCk1WjtgecePE2wAVF+fPlJQkM8277NwUx3r1q3T9OnT9cILLyg2Nla7du3SmDFjNG3aND3++OMVjklJSVFycrLns8vlktPprKuSgYYvL69GTy0DOAcEBUk2m88277NwEx4eLn9/f+Xl5ZVpz8vLU2RkZIVjHn/8cd1555265557JEldu3ZVUVGR7r33Xk2YMEF+fuXnRzscDjkcjprfAeBcERxMuAHQoPjsbim73a4ePXqUmRzsdruVmZmpuLi4CsccP368XIDx9/eXJPlwXjQAAKhHfHpZKjk5WcOHD1fPnj3Vq1cvzZo1S0VFRUpKSpIkDRs2TK1bt1ZaWpokaeDAgZo5c6a6devmuSz1+OOPa+DAgZ6QAwAAzm0+DTeJiYk6cuSIJk2apNzcXMXExCgjI8MzyXj//v1lztRMnDhRNptNEydO1IEDB3Teeedp4MCBevLJJ321CwAAoJ7x6XNufIHn3ABVUFQkhYT8/HcNP6sCAKrDm99vn79+AQAAoCYRbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKX8qnBz4sSJmqoDAACgRngdbtxut6ZNm6bWrVsrJCREe/bskSQ9/vjjevXVV2u8QAAAAG94HW6eeOIJLVy4UE8//bTsdrunvUuXLnrllVdqtDgAAABveR1u3njjDb388ssaOnSo/P39Pe3R0dHasWNHjRYHAADgLa/DzYEDB3ThhReWa3e73Tp58mSNFAUAAFBdXoebzp076+OPPy7Xvnz5cnXr1q1GigIAAKiuRt4OmDRpkoYPH64DBw7I7XZrxYoVysnJ0RtvvKH33nuvNmoEAACoMq/P3AwaNEh///vftXbtWgUHB2vSpEnavn27/v73v+vqq6+ujRoBAACqzOszN5LUt29frVmzpqZrAQAA+NW8PnPTrl07/ec//ynX/uOPP6pdu3Y1UhQAAEB1eR1u9u3bp9LS0nLtxcXFOnDgQI0UBQAAUF1Vviy1cuVKz9+rV69WWFiY53NpaakyMzMVFRVVo8UBAAB4q8rhZvDgwZIkm82m4cOHl/mucePGioqK0rPPPlujxQEAAHiryuHG7XZLktq2bavPP/9c4eHhtVYUAABAdXl9t9TevXtrow4AAIAaUa1bwYuKivThhx9q//79KikpKfPdQw895PX65s6dqxkzZig3N1fR0dGaPXu2evXqVWHfK664Qh9++GG59uuuu06rVq3yetsAAMBavA43W7Zs0XXXXafjx4+rqKhIzZs3V35+voKCgtSiRQuvw016erqSk5M1b948xcbGatasWUpISFBOTo5atGhRrv+KFSvKBKr//Oc/io6O1q233urtrgAAAAvy+lbwhx9+WAMHDtQPP/ygwMBAffrpp/r222/Vo0cPPfPMM14XMHPmTI0YMUJJSUnq3Lmz5s2bp6CgIC1YsKDC/s2bN1dkZKRnWbNmjYKCggg3AABAUjXCTXZ2th555BH5+fnJ399fxcXFcjqdevrpp/XYY495ta6SkhJt2rRJ8fHx/y3Iz0/x8fHKysqq0jpeffVV3X777QoODq7w++LiYrlcrjILAACwLq/DTePGjeXn9/OwFi1aaP/+/ZKksLAwfffdd16tKz8/X6WlpYqIiCjTHhERodzc3LOO37hxo7766ivdc889lfZJS0tTWFiYZ3E6nV7VCAAAGhavw023bt30+eefS5L69eunSZMmacmSJfrjH/+oLl261HiBZ/Lqq6+qa9eulU4+lqSUlBQVFBR4Fm8DGAAAaFi8DjfTp09Xy5YtJUlPPvmkmjVrpgceeEBHjhzRSy+95NW6wsPD5e/vr7y8vDLteXl5ioyMPOPYoqIiLV26VHffffcZ+zkcDoWGhpZZAACAdXl9t1TPnj09f7do0UIZGRnV3rjdblePHj2UmZnpeQKy2+1WZmamRo0adcaxb731loqLi3XHHXdUe/sAAMB6vD5zU5nNmzfrhhtu8HpccnKy5s+fr9dff13bt2/XAw88oKKiIiUlJUmShg0bppSUlHLjXn31VQ0ePFi/+c1vfnXtAADAOrw6c7N69WqtWbNGdrtd99xzj9q1a6cdO3Zo/Pjx+vvf/66EhASvC0hMTNSRI0c0adIk5ebmKiYmRhkZGZ5Jxvv37/dMYD4tJydH69ev1z//+U+vtwcAAKzNZowxVen46quvasSIEWrevLl++OEH/eY3v9HMmTM1evRoJSYmasyYMerUqVNt1/uruVwuhYWFqaCggPk3QGWKiqSQkJ//LiyUKnnUAgDUFW9+v6t8Wer555/Xn//8Z+Xn52vZsmXKz8/XCy+8oC+//FLz5s1rEMEGAABYX5XDze7duz1PAb7pppvUqFEjzZgxQ23atKm14gAAALxV5XDz008/KSgoSJJks9nkcDg8t4QDAADUF15NKH7llVcU8n/X4U+dOqWFCxcqPDy8TJ/qvBUcAACgplR5QnFUVJRsNtuZV2azac+ePTVSWG1hQjFQBUwoBlDPePP7XeUzN/v27fu1dQEAANS6GnuIHwAAQH1AuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJZSrXCze/duTZw4Ub///e91+PBhSdI//vEPff311zVaHAAAgLe8Djcffvihunbtqs8++0wrVqxQYWGhJOmLL75QampqjRcIAADgDa/Dzfjx4/XEE09ozZo1stvtnvarrrpKn376aY0WBwAA4C2vw82XX36p3/3ud+XaW7Roofz8/BopCgAAoLq8DjdNmzbVoUOHyrVv2bJFrVu3rpGiAAAAqsvrcHP77bdr3Lhxys3Nlc1mk9vt1oYNGzR27FgNGzasNmoEAACoMq/DzfTp03XxxRfL6XSqsLBQnTt31uWXX67evXtr4sSJtVEjAABAlVX5reC/tH//fn311VcqLCxUt27ddNFFF9V0bbWCt4IDVcBbwQHUM7XyVvDT1q9fr8suu0znn3++zj///GoXCQAAUBu8vix11VVXqW3btnrssce0bdu22qgJAACg2rwONwcPHtQjjzyiDz/8UF26dFFMTIxmzJih77//vjbqAwAA8IrX4SY8PFyjRo3Shg0btHv3bt166616/fXXFRUVpauuuqo2agQAAKiyX/XizLZt22r8+PF66qmn1LVrV3344Yc1VRcAAEC1VDvcbNiwQQ8++KBatmypIUOGqEuXLlq1alVN1gYAAOA1r++WSklJ0dKlS3Xw4EFdffXVev755zVo0CAFBQXVRn0AAABe8TrcfPTRR/rTn/6k2267TeHh4bVREwAAQLV5HW42bNhQG3UAAADUiCqFm5UrV+raa69V48aNtXLlyjP2vfHGG2ukMAAAgOqo0usX/Pz8lJubqxYtWsjPr/I5yDabTaWlpTVaYE3j9QtAFfD6BQD1TI2/fsHtdlf4NwAAQH3j9a3gb7zxhoqLi8u1l5SU6I033vC6gLlz5yoqKkoBAQGKjY3Vxo0bz9j/xx9/1MiRI9WyZUs5HA516NBB77//vtfbBQAA1uR1uElKSlJBQUG59mPHjikpKcmrdaWnpys5OVmpqanavHmzoqOjlZCQoMOHD1fYv6SkRFdffbX27dun5cuXKycnR/Pnz1fr1q293Q0AAGBRXt8tZYyRzWYr1/79998rLCzMq3XNnDlTI0aM8ISiefPmadWqVVqwYIHGjx9frv+CBQt09OhRffLJJ2rcuLEkKSoqyttdQENnjHT8uK+rsLaiIl9XAADVVuVw061bN9lsNtlsNvXv31+NGv13aGlpqfbu3asBAwZUecMlJSXatGmTUlJSPG1+fn6Kj49XVlZWhWNWrlypuLg4jRw5Uu+++67OO+88DRkyROPGjZO/v3+FY4qLi8tcRnO5XFWuEfWQMdJll0mffOLrSgAA9VSVw83gwYMlSdnZ2UpISFDI6TspJNntdkVFRenmm2+u8obz8/NVWlqqiIiIMu0RERHasWNHhWP27NmjDz74QEOHDtX777+vXbt26cEHH9TJkyeVmppa4Zi0tDRNmTKlynWhnjt+nGBTl/r0kXj6OIAGpsrh5nR4iIqKUmJiogICAmqtqMq43W61aNFCL7/8svz9/dWjRw8dOHBAM2bMqDTcpKSkKDk52fPZ5XLJ6XTWVcmoTXl53KJc24KCpAouQwNAfeb1nJvhw4fXyIbDw8Pl7++vvLy8Mu15eXmKjIyscEzLli3VuHHjMpegOnXqpNzcXJWUlMhut5cb43A45HA4aqRm1DPBwYQbAEA5Vbpbqnnz5srPz5ckNWvWTM2bN690qSq73a4ePXooMzPT0+Z2u5WZmam4uLgKx/Tp00e7du0q86ydnTt3qmXLlhUGGwAAcO6p0pmb5557Tk2aNPH8XdHdUtWRnJys4cOHq2fPnurVq5dmzZqloqIiz91Tw4YNU+vWrZWWliZJeuCBBzRnzhyNGTNGo0eP1jfffKPp06froYceqpF6AABAw1elcPO/l6LuuuuuGtt4YmKijhw5okmTJik3N1cxMTHKyMjwTDLev39/mdc9OJ1OrV69Wg8//LAuueQStW7dWmPGjNG4ceNqrCYAANCwVendUv9r8+bNaty4sbp27SpJevfdd/Xaa6+pc+fOmjx5cr2/PMS7pRo43nkEAOckb36/vX5C8X333aedO3dK+vnW7MTERAUFBemtt97So48+Wr2KAQAAaojX4Wbnzp2KiYmRJL311lvq16+f3nzzTS1cuFB/+9vfaro+AAAAr3gdbowxnruV1q5dq+uuu07Sz/NhTt9RBQAA4Cteh5uePXvqiSee0KJFi/Thhx/q+uuvlyTt3bu33NOGAQAA6prX4WbWrFnavHmzRo0apQkTJujCCy+UJC1fvly9e/eu8QIBAAC84fXdUpU5ceKE/P39PW/rrq+4W6qB424pADgnefP77fXrF07btGmTtm/fLknq3LmzunfvXt1VAQAA1Bivw83hw4eVmJioDz/8UE2bNpUk/fjjj7ryyiu1dOlSnXfeeTVdIwAAQJV5Pedm9OjRKiws1Ndff62jR4/q6NGj+uqrr+RyuXgNAgAA8Dmvz9xkZGRo7dq16tSpk6etc+fOmjt3rq655poaLQ4AAMBbXp+5cbvdFU4abty4cZm3dQMAAPiC1+Hmqquu0pgxY3Tw4EFP24EDB/Twww+rf//+NVocAACAt7wON3PmzJHL5VJUVJTat2+v9u3bq23btnK5XJo9e3Zt1AgAAFBlXs+5cTqd2rx5szIzMz23gnfq1Enx8fE1XhwAAIC3vAo36enpWrlypUpKStS/f3+NHj26tuoCAAColiqHmxdffFEjR47URRddpMDAQK1YsUK7d+/WjBkzarM+AAAAr1R5zs2cOXOUmpqqnJwcZWdn6/XXX9cLL7xQm7UBAAB4rcrhZs+ePRo+fLjn85AhQ3Tq1CkdOnSoVgoDAACojiqHm+LiYgX/z0sK/fz8ZLfb9dNPP9VKYQAAANXh1YTixx9/XEFBQZ7PJSUlevLJJxUWFuZpmzlzZs1VBwAA4KUqh5vLL79cOTk5Zdp69+6tPXv2eD7bbLaaqwwAAKAaqhxu1q1bV4tlAAAA1Ayvn1AMAABQnxFuAACApRBuAACApRBuAACApRBuAACApVQr3Hz88ce64447FBcXpwMHDkiSFi1apPXr19docQAAAN7yOtz87W9/U0JCggIDA7VlyxYVFxdLkgoKCjR9+vQaLxAAAMAbXoebJ554QvPmzdP8+fPVuHFjT3ufPn20efPmGi0OAADAW16Hm5ycHF1++eXl2sPCwvTjjz/WRE0AAADV5nW4iYyM1K5du8q1r1+/Xu3atatWEXPnzlVUVJQCAgIUGxurjRs3Vtp34cKFstlsZZaAgIBqbRcAAFiP1+FmxIgRGjNmjD777DPZbDYdPHhQS5Ys0dixY/XAAw94XUB6erqSk5OVmpqqzZs3Kzo6WgkJCTp8+HClY0JDQ3Xo0CHP8u2333q9XQAAYE1evRVcksaPHy+3263+/fvr+PHjuvzyy+VwODR27FiNHj3a6wJmzpypESNGKCkpSZI0b948rVq1SgsWLND48eMrHGOz2RQZGen1tgAAgPV5febGZrNpwoQJOnr0qL766it9+umnOnLkiKZNm+b1xktKSrRp0ybFx8f/tyA/P8XHxysrK6vScYWFhbrgggvkdDo1aNAgff3115X2LS4ulsvlKrMAAADrqvZD/Ox2uzp37qxevXopJCSkWuvIz89XaWmpIiIiyrRHREQoNze3wjEdO3bUggUL9O6772rx4sVyu93q3bu3vv/++wr7p6WlKSwszLM4nc5q1QoAABoGry9LXXnllbLZbJV+/8EHH/yqgs4mLi5OcXFxns+9e/dWp06d9NJLL1V49iglJUXJycmezy6Xi4ADAICFeR1uYmJiynw+efKksrOz9dVXX2n48OFerSs8PFz+/v7Ky8sr056Xl1flOTWNGzdWt27dKryDS5IcDoccDodXdQEAgIbL63Dz3HPPVdg+efJkFRYWerUuu92uHj16KDMzU4MHD5Ykud1uZWZmatSoUVVaR2lpqb788ktdd911Xm0bAABYU429OPOOO+7QggULvB6XnJys+fPn6/XXX9f27dv1wAMPqKioyHP31LBhw5SSkuLpP3XqVP3zn//Unj17tHnzZt1xxx369ttvdc8999TUrgAAgAbM6zM3lcnKyqrWw/QSExN15MgRTZo0Sbm5uYqJiVFGRoZnkvH+/fvl5/ffDPbDDz9oxIgRys3NVbNmzdSjRw998skn6ty5c03tCgAAaMBsxhjjzYCbbrqpzGdjjA4dOqR///vfevzxx5WamlqjBdY0l8ulsLAwFRQUKDQ01NflwFtFRdLpu/MKC6XgYN/WAwCoE978fnt95iYsLKzMZz8/P3Xs2FFTp07VNddc4+3qAAAAapRX4aa0tFRJSUnq2rWrmjVrVls1AQAAVJtXE4r9/f11zTXX8PZvAABQb3l9t1SXLl20Z8+e2qgFAADgV/M63DzxxBMaO3as3nvvPR06dIj3NgEAgHqlynNupk6dqkceecTzsLwbb7yxzGsYjDGy2WwqLS2t+SoBAACqqMq3gvv7++vQoUPavn37Gfv169evRgqrLdwK3sBxKzgAnJNq5Vbw0xmovocXAABwbvNqzs2Z3gYOAABQH3j1nJsOHTqcNeAcPXr0VxUEAADwa3gVbqZMmVLuCcUAAAD1iVfh5vbbb1eLFi1qqxYAAIBfrcpzbphvAwAAGoIqhxsvXx4OAADgE1W+LOV2u2uzDgAAgBrh9esXAAAA6jPCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsJR6EW7mzp2rqKgoBQQEKDY2Vhs3bqzSuKVLl8pms2nw4MG1WyAAAGgwfB5u0tPTlZycrNTUVG3evFnR0dFKSEjQ4cOHzzhu3759Gjt2rPr27VtHlQIAgIbA5+Fm5syZGjFihJKSktS5c2fNmzdPQUFBWrBgQaVjSktLNXToUE2ZMkXt2rWrw2oBAEB959NwU1JSok2bNik+Pt7T5ufnp/j4eGVlZVU6burUqWrRooXuvvvus26juLhYLperzAIAAKzLp+EmPz9fpaWlioiIKNMeERGh3NzcCsesX79er776qubPn1+lbaSlpSksLMyzOJ3OX103AACov3x+Wcobx44d05133qn58+crPDy8SmNSUlJUUFDgWb777rtarhIAAPhSI19uPDw8XP7+/srLyyvTnpeXp8jIyHL9d+/erX379mngwIGeNrfbLUlq1KiRcnJy1L59+zJjHA6HHA5HLVQPAADqI5+eubHb7erRo4cyMzM9bW63W5mZmYqLiyvX/+KLL9aXX36p7Oxsz3LjjTfqyiuvVHZ2NpecAACAb8/cSFJycrKGDx+unj17qlevXpo1a5aKioqUlJQkSRo2bJhat26ttLQ0BQQEqEuXLmXGN23aVJLKtQMAgHOTz8NNYmKijhw5okmTJik3N1cxMTHKyMjwTDLev3+//Pwa1NQgAADgQzZjjPF1EXXJ5XIpLCxMBQUFCg0N9XU58FZRkRQS8vPfhYVScLBv6wEA1Alvfr85JQIAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACylXoSbuXPnKioqSgEBAYqNjdXGjRsr7btixQr17NlTTZs2VXBwsGJiYrRo0aI6rBYAANRnPg836enpSk5OVmpqqjZv3qzo6GglJCTo8OHDFfZv3ry5JkyYoKysLG3dulVJSUlKSkrS6tWr67hyAABQH9mMMcaXBcTGxurSSy/VnDlzJElut1tOp1OjR4/W+PHjq7SO7t276/rrr9e0adPO2tflciksLEwFBQUKDQ39VbXDB4qKpJCQn/8uLJSCg31bDwCgTnjz++3TMzclJSXatGmT4uPjPW1+fn6Kj49XVlbWWccbY5SZmamcnBxdfvnlFfYpLi6Wy+UqswAAAOvyabjJz89XaWmpIiIiyrRHREQoNze30nEFBQUKCQmR3W7X9ddfr9mzZ+vqq6+usG9aWprCwsI8i9PprNF9AAAA9YvP59xUR5MmTZSdna3PP/9cTz75pJKTk7Vu3boK+6akpKigoMCzfPfdd3VbLAAAqFONfLnx8PBw+fv7Ky8vr0x7Xl6eIiMjKx3n5+enCy+8UJIUExOj7du3Ky0tTVdccUW5vg6HQw6Ho0brBgAA9ZdPz9zY7Xb16NFDmZmZnja3263MzEzFxcVVeT1ut1vFxcW1USIAAGhgfHrmRpKSk5M1fPhw9ezZU7169dKsWbNUVFSkpKQkSdKwYcPUunVrpaWlSfp5Dk3Pnj3Vvn17FRcX6/3339eiRYv04osv+nI3AABAPeHzcJOYmKgjR45o0qRJys3NVUxMjDIyMjyTjPfv3y8/v/+eYCoqKtKDDz6o77//XoGBgbr44ou1ePFiJSYm+moXAABAPeLz59zUNZ5z08DxnBsAOCc1mOfcAAAA1DTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsJR6EW7mzp2rqKgoBQQEKDY2Vhs3bqy07/z589W3b181a9ZMzZo1U3x8/Bn7AwCAc4vPw016erqSk5OVmpqqzZs3Kzo6WgkJCTp8+HCF/detW6ff//73+te//qWsrCw5nU5dc801OnDgQB1XDgAA6iObMcb4soDY2FhdeumlmjNnjiTJ7XbL6XRq9OjRGj9+/FnHl5aWqlmzZpozZ46GDRt21v4ul0thYWEqKChQaGjor67fwxjp+PGaWx8qVlQkRUT8/HdhoRQc7Nt6AAB1wpvf70Z1VFOFSkpKtGnTJqWkpHja/Pz8FB8fr6ysrCqt4/jx4zp58qSaN29e4ffFxcUqLi72fHa5XL+u6MoLkUJCamfdAACgynx6WSo/P1+lpaWKOP3/xP9PRESEcnNzq7SOcePGqVWrVoqPj6/w+7S0NIWFhXkWp9P5q+tGPdCnjxQU5OsqAAD1kE/P3PxaTz31lJYuXap169YpICCgwj4pKSlKTk72fHa5XLUTcIKCfr5MgroRFCTZbL6uAgBQD/k03ISHh8vf3195eXll2vPy8hQZGXnGsc8884yeeuoprV27Vpdcckml/RwOhxwOR43Ue0Y2G/M/AACoB3x6Wcput6tHjx7KzMz0tLndbmVmZiouLq7ScU8//bSmTZumjIwM9ezZsy5KBQAADYTPL0slJydr+PDh6tmzp3r16qVZs2apqKhISUlJkqRhw4apdevWSktLkyT9+c9/1qRJk/Tmm28qKirKMzcnJCREIUzoBQDgnOfzcJOYmKgjR45o0qRJys3NVUxMjDIyMjyTjPfv3y8/v/+eYHrxxRdVUlKiW265pcx6UlNTNXny5LosHQAA1EM+f85NXau159wAAIBa483vt8+fUAwAAFCTCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSfP76hbp2+oHMLpfLx5UAAICqOv27XZUXK5xz4ebYsWOSJKfT6eNKAACAt44dO6awsLAz9jnn3i3ldrt18OBBNWnSRDabrUbX7XK55HQ69d133/HeqlrEca4bHOe6wXGuOxzrulFbx9kYo2PHjqlVq1ZlXqhdkXPuzI2fn5/atGlTq9sIDQ3lfzh1gONcNzjOdYPjXHc41nWjNo7z2c7YnMaEYgAAYCmEGwAAYCmEmxrkcDiUmpoqh8Ph61IsjeNcNzjOdYPjXHc41nWjPhznc25CMQAAsDbO3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3Hhp7ty5ioqKUkBAgGJjY7Vx48Yz9n/rrbd08cUXKyAgQF27dtX7779fR5U2bN4c5/nz56tv375q1qyZmjVrpvj4+LP+94KfefvP82lLly6VzWbT4MGDa7dAi/D2OP/4448aOXKkWrZsKYfDoQ4dOvDvjirw9jjPmjVLHTt2VGBgoJxOpx5++GGdOHGijqptmD766CMNHDhQrVq1ks1m0zvvvHPWMevWrVP37t3lcDh04YUXauHChbVepwyqbOnSpcZut5sFCxaYr7/+2owYMcI0bdrU5OXlVdh/w4YNxt/f3zz99NNm27ZtZuLEiaZx48bmyy+/rOPKGxZvj/OQIUPM3LlzzZYtW8z27dvNXXfdZcLCwsz3339fx5U3LN4e59P27t1rWrdubfr27WsGDRpUN8U2YN4e5+LiYtOzZ09z3XXXmfXr15u9e/eadevWmezs7DquvGHx9jgvWbLEOBwOs2TJErN3716zevVq07JlS/Pwww/XceUNy/vvv28mTJhgVqxYYSSZt99++4z99+zZY4KCgkxycrLZtm2bmT17tvH39zcZGRm1Wifhxgu9evUyI0eO9HwuLS01rVq1MmlpaRX2v+2228z1119fpi02Ntbcd999tVpnQ+ftcf6lU6dOmSZNmpjXX3+9tkq0hOoc51OnTpnevXubV155xQwfPpxwUwXeHucXX3zRtGvXzpSUlNRViZbg7XEeOXKkueqqq8q0JScnmz59+tRqnVZSlXDz6KOPmt/+9rdl2hITE01CQkItVmYMl6WqqKSkRJs2bVJ8fLynzc/PT/Hx8crKyqpwTFZWVpn+kpSQkFBpf1TvOP/S8ePHdfLkSTVv3ry2ymzwqnucp06dqhYtWujuu++uizIbvOoc55UrVyouLk4jR45URESEunTpounTp6u0tLSuym5wqnOce/furU2bNnkuXe3Zs0fvv/++rrvuujqp+Vzhq9/Bc+7FmdWVn5+v0tJSRURElGmPiIjQjh07KhyTm5tbYf/c3Nxaq7Ohq85x/qVx48apVatW5f4Hhf+qznFev369Xn31VWVnZ9dBhdZQneO8Z88effDBBxo6dKjef/997dq1Sw8++KBOnjyp1NTUuii7wanOcR4yZIjy8/N12WWXyRijU6dO6f7779djjz1WFyWfMyr7HXS5XPrpp58UGBhYK9vlzA0s5amnntLSpUv19ttvKyAgwNflWMaxY8d05513av78+QoPD/d1OZbmdrvVokULvfzyy+rRo4cSExM1YcIEzZs3z9elWcq6des0ffp0vfDCC9q8ebNWrFihVatWadq0ab4uDTWAMzdVFB4eLn9/f+Xl5ZVpz8vLU2RkZIVjIiMjveqP6h3n05555hk99dRTWrt2rS655JLaLLPB8/Y47969W/v27dPAgQM9bW63W5LUqFEj5eTkqH379rVbdANUnX+eW7ZsqcaNG8vf39/T1qlTJ+Xm5qqkpER2u71Wa26IqnOcH3/8cd1555265557JEldu3ZVUVGR7r33Xk2YMEF+fvx//5pQ2e9gaGhorZ21kThzU2V2u109evRQZmamp83tdiszM1NxcXEVjomLiyvTX5LWrFlTaX9U7zhL0tNPP61p06YpIyNDPXv2rItSGzRvj/PFF1+sL7/8UtnZ2Z7lxhtv1JVXXqns7Gw5nc66LL/BqM4/z3369NGuXbs84VGSdu7cqZYtWxJsKlGd43z8+PFyAeZ0oDS8crHG+Ox3sFanK1vM0qVLjcPhMAsXLjTbtm0z9957r2natKnJzc01xhhz5513mvHjx3v6b9iwwTRq1Mg888wzZvv27SY1NZVbwavA2+P81FNPGbvdbpYvX24OHTrkWY4dO+arXWgQvD3Ov8TdUlXj7XHev3+/adKkiRk1apTJyckx7733nmnRooV54oknfLULDYK3xzk1NdU0adLE/PWvfzV79uwx//znP0379u3Nbbfd5qtdaBCOHTtmtmzZYrZs2WIkmZkzZ5otW7aYb7/91hhjzPjx482dd97p6X/6VvA//elPZvv27Wbu3LncCl4fzZ4925x//vnGbrebXr16mU8//dTzXb9+/czw4cPL9F+2bJnp0KGDsdvt5re//a1ZtWpVHVfcMHlznC+44AIjqdySmppa94U3MN7+8/y/CDdV5+1x/uSTT0xsbKxxOBymXbt25sknnzSnTp2q46obHm+O88mTJ83kyZNN+/btTUBAgHE6nebBBx80P/zwQ90X3oD861//qvDft6eP7fDhw02/fv3KjYmJiTF2u920a9fOvPbaa7Vep80Yzr8BAADrYM4NAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINgDIWLlyopk2b+rqMarPZbHrnnXfO2Oeuu+7S4MGD66QeAHWPcANY0F133SWbzVZu2bVrl69L08KFCz31+Pn5qU2bNkpKStLhw4drZP2HDh3StddeK0nat2+fbDabsrOzy/R5/vnntXDhwhrZXmUmT57s2U9/f385nU7de++9Onr0qFfrIYgB3uOt4IBFDRgwQK+99lqZtvPOO89H1ZQVGhqqnJwcud1uffHFF0pKStLBgwe1evXqX73us709XpLCwsJ+9Xaq4re//a3Wrl2r0tJSbd++XX/4wx9UUFCg9PT0Otk+cK7izA1gUQ6HQ5GRkWUWf39/zZw5U127dlVwcLCcTqcefPBBFRYWVrqeL774QldeeaWaNGmi0NBQ9ejRQ//+9789369fv159+/ZVYGCgnE6nHnroIRUVFZ2xNpvNpsjISLVq1UrXXnutHnroIa1du1Y//fST3G63pk6dqjZt2sjhcCgmJkYZGRmesSUlJRo1apRatmypgIAAXXDBBUpLSyuz7tOXpdq2bStJ6tatm2w2m6644gpJZc+GvPzyy2rVqlWZt3BL0qBBg/SHP/zB8/ndd99V9+7dFRAQoHbt2mnKlCk6derUGfezUaNGioyMVOvWrRUfH69bb71Va9as8XxfWlqqu+++W23btlVgYKA6duyo559/3vP95MmT9frrr+vdd9/1nAVat26dJOm7777TbbfdpqZNm6p58+YaNGiQ9u3bd8Z6gHMF4QY4x/j5+ekvf/mLvv76a73++uv64IMP9Oijj1baf+jQoWrTpo0+//xzbdq0SePHj1fjxo0lSbt379aAAQN08803a+vWrUpPT9f69es1atQor2oKDAyU2+3WqVOn9Pzzz+vZZ5/VM888o61btyohIUE33nijvvnmG0nSX/7yF61cuVLLli1TTk6OlixZoqioqArXu3HjRknS2rVrdejQIa1YsaJcn1tvvVX/+c9/9K9//cvTdvToUWVkZGjo0KGSpI8//ljDhg3TmDFjtG3bNr300ktauHChnnzyySrv4759+7R69WrZ7XZPm9vtVps2bfTWW29p27ZtmjRpkh577DEtW7ZMkjR27FjddtttGjBggA4dOqRDhw6pd+/eOnnypBISEtSkSRN9/PHH2rBhg0JCQjRgwACVlJRUuSbAsmr91ZwA6tzw4cONv7+/CQ4O9iy33HJLhX3feust85vf/Mbz+bXXXjNhYWGez02aNDELFy6scOzdd99t7r333jJtH3/8sfHz8zM//fRThWN+uf6dO3eaDh06mJ49expjjGnVqpV58skny4y59NJLzYMPPmiMMWb06NHmqquuMm63u8L1SzJvv/22McaYvXv3Gklmy5YtZfr88o3mgwYNMn/4wx88n1966SXTqlUrU1paaowxpn///mb69Oll1rFo0SLTsmXLCmswxpjU1FTj5+dngoODTUBAgOftyTNnzqx0jDHGjBw50tx8882V1np62x07dixzDIqLi01gYKBZvXr1GdcPnAuYcwNY1JVXXqkXX3zR8zk4OFjSz2cx0tLStGPHDrlcLp06dUonTpzQ8ePHFRQUVG49ycnJuueee7Ro0SLPpZX27dtL+vmS1datW7VkyRJPf2OM3G639u7dq06dOlVYW0FBgUJCQuR2u3XixAlddtlleuWVV+RyuXTw4EH16dOnTP8+ffroiy++kPTzJaWrr75aHTt21IABA3TDDTfommuu+VXHaujQoRoxYoReeOEFORwOLVmyRLfffrv8/Pw8+7lhw4YyZ2pKS0vPeNwkqWPHjlq5cqVOnDihxYsXKzs7W6NHjy7TZ+7cuVqwYIH279+vn376SSUlJYqJiTljvV988YV27dqlJk2alGk/ceKEdu/eXY0jAFgL4QawqODgYF144YVl2vbt26cbbrhBDzzwgJ588kk1b95c69ev1913362SkpIKf6QnT56sIUOGaNWqVfrHP/6h1NRULV26VL/73e9UWFio++67Tw899FC5ceeff36ltTVp0kSbN2+Wn5+fWrZsqcDAQEmSy+U66351795de/fu1T/+8Q+tXbtWt912m+Lj47V8+fKzjq3MwIEDZYzRqlWrdOmll+rjjz/Wc8895/m+sLBQU6ZM0U033VRubEBAQKXrtdvtnv8OnnrqKV1//fWaMmWKpk2bJklaunSpxo4dq2effVZxcXFq0qSJZsyYoc8+++yM9RYWFqpHjx5lQuVp9WXSOOBLhBvgHLJp0ya53W49++yznrMSp+d3nEmHDh3UoUMHPfzww/r973+v1157Tb/73e/UvXt3bdu2rVyIOhs/P78Kx4SGhqpVq1basGGD+vXr52nfsGGDevXqVaZfYmKiEhMTdcstt2jAgAE6evSomjdvXmZ9p+e3lJaWnrGegIAA3XTTTVqyZIl27dqljh07qnv37p7vu3fvrpycHK/385cmTpyoq666Sg888IBnP3v37q0HH3zQ0+eXZ17sdnu5+rt376709HS1aNFCoaGhv6omwIqYUAycQy688EKdPHlSs2fP1p49e7Ro0SLNmzev0v4//fSTRo0apXXr1unbb7/Vhg0b9Pnnn3suN40bN06ffPKJRo0apezsbH3zzTd69913vZ5Q/L/+9Kc/6c9//rPS09OVk5Oj8ePHKzs7W2PGjJEkzZw5U3/961+1Y8cO7dy5U2+99ZYiIyMrfPBgixYtFBgYqIyMDOXl5amgoKDS7Q4dOlSrVq3SggULPBOJT5s0aZLeeOMNTZkyRV9//bW2b9+upUuXauLEiV7tW1xcnC655BJNnz5dknTRRRfp3//+t1avXq2dO3fq8ccf1+eff15mTFRUlLZu3aqcnBzl5+fr5MmTGjp0qMLDwzVo0CB9/PHH2rt3r9atW6eHHnpI33//vVc1AZbk60k/AGpeRZNQT5s5c6Zp2bKlCQwMNAkJCeaNN94wkswPP/xgjCk74be4uNjcfvvtxul0Grvdblq1amVGjRpVZrLwxo0bzdVXX21CQkJMcHCwueSSS8pNCP5fv5xQ/EulpaVm8uTJpnXr1qZx48YmOjra/OMf//B8//LLL5uYmBgTHBxsQkNDTf/+/c3mzZs93+t/JhQbY8z8+fON0+k0fn5+pl+/fpUen9LSUtOyZUsjyezevbtcXRkZGaZ3794mMDDQhIaGml69epmXX3650v1ITU010dHR5dr/+te/GofDYfbv329OnDhh7rrrLhMWFmaaNm1qHnjgATN+/Pgy4w4fPuw5vpLMv/71L2OMMYcOHTLDhg0z4eHhxuFwmHbt2pkRI0aYgoKCSmsCzhU2Y4zxbbwCAACoOVyWAgAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlvL/AUcQQVH304hdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df['FPR'], df['TPR'], color='red')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.13 Es difícil evaluar la precisión de la clasificación cuando los objetos de\n",
    "datos individuales pueden pertenecer a más de una clase a la vez. En tales\n",
    "casos, comente qué criterios usaría para comparar diferentes clasificadores\n",
    "modelados a partir de los mismos datos.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Un objeto de datos puede pertenecer a más de una clase a la vez. Sin embargo,\n",
    "ese objeto de datos pertenecerá a algunas clases con más frecuencia que a otras\n",
    "clases. Por lo tanto, un criterio que se puede utilizar para evaluar la\n",
    "precisión de la clasificación es elegir el clasificador que predice la clase a\n",
    "la que normalmente pertenece el objeto de datos. Alternativamente, se puede usar\n",
    "una heurística de segunda suposición, mediante la cual una predicción de clase\n",
    "se considera correcta si concuerda con la primera o la segunda clase más\n",
    "probable. Otros criterios que se pueden usar para comparar diferentes\n",
    "clasificadores modelados a partir de los mismos datos incluyen la velocidad, la\n",
    "solidez, la escalabilidad y la interpretabilidad.\n",
    "\n",
    "En general, preferimos clasificadores que minimicen los costos computacionales (p. ej., tiempo de entrenamiento, tiempo de clasificación), hagan predicciones precisas incluso cuando se les proporcionen datos confusos o incompletos, funcionen de manera eficiente con grandes cantidades de datos y brinden resultados concisos que sean fáciles de entender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.14 Supongamos que queremos seleccionar entre dos modelos de predicción, M1 y M2. Hemos realizado 10 rondas de validación cruzada 10 veces en cada modelo, donde se utiliza la misma partición de datos en la ronda i tanto para M1 como para M2. Las tasas de error obtenidas para M1 son 30,5, 32,2, 20,7, 20,6, 31,0, 41,0, 27,7, 26,0, 21,5, 26,0. Las tasas de error para M2 son 22,4, 14,5, 22,4, 19,6, 20,7, 20,4, 22,1, 19,4, 16,2, 35,0. Comente si un modelo es significativamente mejor que el otro considerando un nivel de significancia del 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.15 ¿Qué es _boosting_? Indique por qué puede mejorar la precisión de la\n",
    "inducción del árbol de decisiones.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "El _boosting_ es un método de aprendizaje automático que combina varios modelos\n",
    "de aprendizaje débiles para crear un modelo de aprendizaje fuerte. En _boosting_ \n",
    "un ensamble de modelos de aprendizaje débiles se construye de manera secuencial,\n",
    "cada predictor trata de corregir los errores de su predecesor.\n",
    "\n",
    "En _boosting_ cada predictor pone más atención a las instancias que fueron mal\n",
    "clasificadas por su predecesor mediante el ajuste de los pesos de las instancias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.16 Métodos resumidos para abordar el problema del desequilibrio de clases.\n",
    "Supongamos que un banco quiere desarrollar un clasificador que proteja contra\n",
    "transacciones fraudulentas con tarjetas de crédito. Ilustre cómo se puede\n",
    "inducir un clasificador de calidad basándose en un gran conjunto de ejemplos no\n",
    "fraudulentos y un conjunto muy pequeño de casos fraudulentos.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "1. Submuestreo: consiste en seleccionar un subconjunto de tuplas de la clase\n",
    "   mayoritaria de manera aleatoria. Este método puede ser útil cuando tenemos\n",
    "   una gran cantidad de tuplas de la clase mayoritaria.\n",
    "\n",
    "2. Sobremuestreo: consiste en replicar tuplas de la clase minoritaria de manera\n",
    "   aleatoria. Este método puede ser útil cuando tenemos una gran cantidad de\n",
    "   tuplas de la clase minoritaria.\n",
    "\n",
    "3. Generación sintética de instancias: consiste en generar nuevas tuplas de la\n",
    "   clase minoritaria. Este método puede ser útil cuando tenemos una gran\n",
    "   cantidad de tuplas de la clase minoritaria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
